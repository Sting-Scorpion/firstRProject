---
title: "Assignment 6"
author: "Louis Wang"
date: "2022-11-09"
output: html_document # you can change to other output format if you want
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# 1. Continuous random variables and limit laws

## 1.1 (Q1)
\(P(U\in[a,b])=\int_a^bp_U(x)dx=\frac{1}{1-0}(b-a)=b-a\)

## 1.1 (Q2)
```{r}
set.seed(0)
n <- 1000
sample_X <- data.frame(U=runif(n)) %>%
  mutate(X=case_when(
    (0<=U)&(U<0.25)~3,
    (0.25<=U)&(U<0.5)~10,
    (0.5<=U)&(U<=1)~0)) %>%
  pull(X)
```
\(The\ numbers\ in\ sample_X\ are\ generated\ from\ the\ distribution\ of\ X,\ with\ P(X=3)=P(\bigcup\in[0, 0.25)=1/4,\ P(X=10)=P(\bigcup\in[0.25, 0.5)=1/4,\ andP(X=0)=P(\bigcup\in[0.5, 1])=1/2.\)
\(So\ the\ sample\ sample_X\ can\ be\ viewed\ as\ a\ sequence\ of\ i.i.d.\ copies\ X1, X2, · · · , Xn.\)

## 1.1 (Q3)
```{r}
sample_X_0310 <- function(alpha, beta, n){
  set.seed(1)
  sample_0310 <- data.frame(U=runif(n)) %>%
    mutate(X=case_when(
      (0<=U)&(U<alpha)~3,
      (alpha<=U)&(U<alpha+beta)~10,
      (alpha+beta<=U)&(U<=1)~0
    )) %>%
    pull(X)
  return (sample_0310)
}
sample_X_0310(0.25,0.25,10)
```

## 1.1 (Q4)
```{r}
sample4 <- sample_X_0310(0.5,0.1,10000)
mean(sample4)
```
The sample average is so close to the theoretical value of E(X)=2.5, since the sample size is large enough to reach the theroretical value.

## 1.1 (Q5)
```{r}
var(sample4)
```
The population variance Var(X)=8.25

## 1.1 (Q6)
```{r}
beta = seq(0, 0.9, 0.01)
samples <- data.frame(beta) %>%
  mutate(sample_X = map(beta, ~sample_X_0310(0.1,.x,100))) %>%
  mutate(samplemean = map_dbl(sample_X, mean)) %>%
  mutate(Expectation = 0.3 + 10 * beta)
```

## 1.1 (Q7)
```{r}
samples %>% pivot_longer(cols=c("samplemean","Expectation"),
                         names_to="name", values_to="value") %>%
  ggplot(aes(beta, value, color=name)) +
  geom_point()
```

## 1.2 (Q1)
\(For\ \int_{-\infty}^{+\infty}p_\lambda(x)dx=1\ and P(X\in[a,b])=\int_a^bp_\lambda(x)dx,\ p_\lambda is\ a\ well-defined\ probability\ density\ function\)  
$$F_\lambda(x)=\begin{cases}
1-e^{-\lambda x}, & x\geq 0\\
0, & x<0
\end{cases}$$  
$$F_\lambda^{-1}(p)=-\frac{ln(1-p)}{\lambda}$$

## 1.2 (Q2)
```{r}
my_cdf_exp <- function(x, lambda){
  result <- 0
  if(x >= 0){
    result <- 1-exp(-1*lambda*x)
  }
  return(result)
}

lambda <- 1/2
map_dbl(.x=seq(-1,4), .f=~my_cdf_exp(x=.x,lambda=lambda) )

test_inputs <- seq(-1,10,0.1)
my_cdf_output <- map_dbl(.x=test_inputs, .f=~my_cdf_exp(x=.x,lambda=lambda))
inbuilt_cdf_output <- map_dbl(.x=test_inputs,.f=~pexp(q=.x,rate=lambda))
all.equal(my_cdf_output,inbuilt_cdf_output)
```

## 1.2 (Q3)
```{r}
my_quantile_exp <- function(p, lambda){
  result <- -1*log(1-p)/lambda
  return (result)
}

test_input <- seq(0.01, 0.99, 0.01)
my_quantile_output <- map_dbl(.x=test_input, .f=~my_quantile_exp(p=.x,lambda=lambda))
inbuilt_quantile_output <- map_dbl(.x=test_input, .f=~qexp(p=.x,rate=lambda))
all.equal(my_quantile_output,inbuilt_quantile_output)
```

## 1.2 (Q4)
\(E(X)=\int_{-\infty}^{+\infty}xp_\lambda(x)dx=\int_0^{+\infty}\lambda xe^{-\lambda x}dx=\frac{1}{\lambda}\int_0^\infty \lambda xe^{-\lambda x}d(\lambda x)=\frac{1}{\lambda}\int_0^\infty te^{-t}dt=\frac{1}{\lambda}\)
\(Var(x)=E(X^2)-E^2(X)=\int_{-\infty}^{+\infty}x^2p_\lambda(x)dx-\frac{1}{\lambda^2}=\int_0^{+\infty}\lambda x^2e^{-\lambda x}dx-\frac{1}{\lambda^2}=\frac{1}{\lambda^2}\int_0^\infty(\lambda x)^2e^{-\lambda x}d(\lambda x)-\frac{1}{\lambda^2}=\frac{1}{\lambda^2}\)

## 1.3 (Q1)
$$E(X)=np$$
$$Var(X)=np(1-p)$$

## 1.3 (Q2)
```{r}
binom_df <- data.frame(x = seq(0, 50, 1)) %>%
  mutate(pmf = map_dbl(x, ~dbinom(x=.x,50,0.7)))
head(binom_df, 3)
```

## 1.3 (Q3)
```{r}
gaussian_df <- data.frame(x=seq(0,50,0.01)) %>%
  mutate(pdf=map_dbl(x, ~dnorm(x=.x,35,sqrt(10.5))))
head(gaussian_df, 3)
```

## 1.3 (Q4)
```{r}
colors<-c("Gaussian pdf"="red", "Binomial pmf"="blue")
fill<-c("Gaussian pdf"="white", "Binomial pmf"="white")

ggplot() + labs(x="x",y="Probability") + theme_bw() +
  # create plot of Gaussian density
  geom_line(data=gaussian_df, aes(x,y=pdf,color="Gaussian pdf"),size=2) +
  # create a bar chart from PMF of Binomial distribution
  geom_col(data=binom_df, aes(x=x,y=pmf, color="Binomial pmf",fill="Binomial pmf")) +
  # set color
  scale_color_manual(name = "myLegend", values=colors) +
  scale_fill_manual(name = "myLegend", values=fill) +
  xlim(c(20,50))
```
Because the distribution of a sample variable approximates a normal distribution as the sample size becomes larger.

## 1.4 (Q1)
```{r}
# Generate a plot which displays the probability density function for three Gaussian random variables
# the density function; Alternatively, you can use the function dnorm
f_musigma <- function(mu, sigma, x){
  y = (1/sigma/sqrt(2*pi)) * exp(-0.5*((x-mu)/sigma)^2)
  return (y)
}

df_density <- data.frame( x = seq(-4, 6, 0.1) ) %>%
  mutate( '1' = f_musigma(mu=1,sigma=1,x=x),
          '2' = f_musigma(mu=1,sigma=sqrt(2),x=x),
          '3' = dnorm(x, mean=1, sd=sqrt(3)) )

df_density_longer = pivot_longer(df_density, col = c('1','2','3'),
                                 names_to = 'Variance', values_to = 'Density')

ggplot(df_density_longer, aes(x=x, y=Density, linetype=Variance, color=Variance)) +
  geom_line() + theme_bw()
```

## 1.4 (Q2)
```{r}
# Generate a plot which displays the cumulative distribution function for three Gaussian random
df <- data.frame( x = seq(-4, 6, 0.1) ) %>%
  mutate( '1' = pnorm(mean=1,sd=1,q=x),
          '2' = pnorm(mean=1,sd=sqrt(2),q=x),
          '3' = pnorm(mean=1,sd=sqrt(3),q=x) )

df_longer = pivot_longer(df, col = c('1','2','3'),
                         names_to = 'Variance', values_to = 'CDF')

ggplot(df_longer, aes(x=x, y=CDF, linetype=Variance, color=Variance)) +
  geom_line() + theme_bw() + ylab('Cumulative distribution function')
```

## 1.4 (Q3)
```{r}
# Generate a plot for the quantile function for the same three Gaussian distributions as above.
df <- data.frame( x = seq(0, 1, 0.005) ) %>%
  mutate( '1' = qnorm(mean=1,sd=1,p=x),
          '2' = qnorm(mean=1,sd=sqrt(2),p=x),
          '3' = qnorm(mean=1,sd=sqrt(3),p=x) )

df_longer = pivot_longer(df, col = c('1','2','3'),
                         names_to = 'Variance', values_to = 'Quantile')

ggplot(df_longer, aes(x=x, y = Quantile, linetype=Variance, color=Variance)) +
  geom_line() + theme_bw()
```

__Describe the relationship between the quantile function and the cumulative distribution function.__  
**Answer: The quantile function is the inverse of the cumulative distribution function in this case.**

## 1.4 (Q4)
```{r}
# Now use rnorm() to generate a random independent and identically distributed sequence
set.seed(0)
# Store your random sample in a vector called “standardGaussianSample”.
standardGaussianSample = rnorm(100, mean=0, sd=1)
head(standardGaussianSample)
```

## 1.4 (Q5)
\(Y_i\in N(1,3),\ Y_i=\alpha*Z_i+\beta\)
```{r}
mean1Var3GaussianSampleA = standardGaussianSample*sqrt(3) + 1
head(mean1Var3GaussianSampleA)
```

## 1.4 (Q6)
\(Y_i\in N(1,3),\ using\ the\ rnorm()\ function\)
```{r}
set.seed(0)
mean1Var3GaussianSampleB = rnorm(100, mean=1, sd=sqrt(3))
head(mean1Var3GaussianSampleB)

# Are the entries of the vectors mean1Var3GaussianSampleA and mean1Var3GaussianSampleB the same?
all.equal(mean1Var3GaussianSampleA, mean1Var3GaussianSampleB)
```

## 1.4 (Q7)
```{r}
colors<-c("Population density"="red", "Sample kernel density"="blue",
          "Population mean"="green", "Sample mean"="violet")
linetypes<-c("Population density"="solid", "Sample kernel density"="dashed",
             "Population mean"="solid", "Sample mean"="dashed")
ggplot() + labs(x="x",y="Density") + theme_bw() +
  # 1. create plot of theoretical density
  geom_line(data=select(df_density, x, "3"),
            aes(x=x,y=`3`,color="Population density",
                linetype="Population density")) +
  # 2. add in kernel density plot from real sample
  geom_density(data=data.frame(x=mean1Var3GaussianSampleA),
               aes(x=x,color="Sample kernel density",
                   linetype="Sample kernel density")) +
  # 3. vertical lines
  geom_vline(aes(xintercept=1,color="Population mean",
                 linetype="Population mean")) +
  geom_vline(aes(xintercept=mean(mean1Var3GaussianSampleA),
                 color="Sample mean",linetype="Sample mean")) +
  # 4.
  scale_color_manual(name = "Legend", values=colors) +
  scale_linetype_manual(name="Legend", values=linetypes)
```



# 2. Location estimators with Gaussian data
```{r}
set.seed(0)
num_trials_per_sample_size <- 1000
min_sample_size <- 30
max_sample_size <- 500
sample_size_inc <- 5
mu_0 <- 1
sigma_0 <- 3

# create data frame of all pairs of sample_size and trial
simulation_df<-crossing(trial=seq(num_trials_per_sample_size),
                        sample_size=seq(min_sample_size,
                                        max_sample_size,sample_size_inc)) %>%
  # simulate sequences of Gaussian random variables
  mutate(simulation=pmap(.l=list(trial,sample_size),
                         .f=~rnorm(.y,mean=mu_0,sd=sigma_0))) %>%
  # compute the sample medians
  mutate(sample_md=map_dbl(.x=simulation,.f=median)) %>%
  group_by(sample_size) %>%
  summarise(msq_error_md=mean((sample_md-mu_0)^2))
```


## 2 (Q1)
The population median is equal to the 0.5-quantile and hence is equal to $\mu_0$

## 2 (Q2)
Modify the above code to include estimates of the mean square error of the sample mean. Your data frame simulation_df should have a new column called msq_error_mn which estimates the mean squared error of the sample mean as an estimator of µ0.  
Then generate a plot which includes both the mean square error of the sample mean and the sample median as a function of the sample size.
```{r}
set.seed(0)
num_trials_per_sample_size <- 1000
min_sample_size <- 30
max_sample_size <- 500
sample_size_inc <- 5
mu_0 <- 1
sigma_0 <- 3

# create data frame of all pairs of sample_size and trial
simulation_df<-crossing(trial=seq(num_trials_per_sample_size),
                        sample_size=seq(min_sample_size,
                                        max_sample_size,sample_size_inc)) %>%
  # simulate sequences of Gaussian random variables
  mutate(simulation=pmap(.l=list(trial,sample_size),
                         .f=~rnorm(.y,mean=mu_0,sd=sigma_0))) %>%
  # compute the sample medians
  mutate(sample_md=map_dbl(.x=simulation,.f=median)) %>%
  mutate(sample_mn=map_dbl(.x=simulation,.f=mean)) %>%
  group_by(sample_size) %>%
  summarise(msq_error_md=mean((sample_md-mu_0)^2), msq_error_mn=mean((sample_mn-mu_0)^2))

simulation_df %>%
  pivot_longer(cols=c(msq_error_md,msq_error_mn),
               names_to="Estimator",values_to="msq_error") %>%
  mutate(Estimator=case_when(Estimator=="msq_error_md"~"Median",
                             Estimator=="msq_error_mn"~"Mean")) %>%
  ggplot(aes(x=sample_size,y=msq_error,color=Estimator,linetype=Estimator)) +
  geom_smooth()+theme_bw()+xlab("Sample size")+ylab("Mean square error")
```

# 3. (**) The law of large numbers and Hoeffding’s inequality

## 3 (Q1)





